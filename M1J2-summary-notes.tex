\documentclass{article}
\title{M1J2 Summary Notes (JMC Year 1, 2017/2018 syllabus)}
\date{}
\author{Fawaz Shah}

% Packages for adding hyperlinks to table of contents
\usepackage{color}   %May be necessary if you want to color links
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=black,  %choose some color if you want links to stand out
}

%package that allows aligned equations
\usepackage{amsmath}

%package that allows notation for popular sets (N, R, Q, etc.)
\usepackage{amssymb}

%renaming commands for natural and real number sets for ease of use
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

%package for managing images
\usepackage{graphicx}
\graphicspath{ {img/} }

%package for managing hyperlinks
\usepackage{hyperref}

\begin{document}
\large
\maketitle
\begin{center}
(STILL UNDER CONSTRUCTION)
\end{center}
\noindent Dr Lawn refers to propositions, theorems, corollaries and lemmas. In this document I will refer to them all as 'theorems'.
\\\\
\noindent This document contains a list of definitions and a list of theorems.
\tableofcontents
\newpage
\part{Abstract Linear Algebra}

\section{Definitions}
\paragraph{Vector space}

\section{Theorems}

\newpage
\part{Group Theory}

\section{Definitions}

\section{Theorems}

\newpage
\part{Analysis}

\section{Definitions}
\paragraph{Sequence}
A sequence is simply a map $ f: \N \to \R $, denoted by $ a_{n} $
\paragraph{Convergence (as $ n \to \infty $)}
A sequence $ a_{n} $ converges to a limit L if for all real numbers $ \epsilon > 0 $, there exists an $ N \in \N $ such that for all $ n > N $ we have $ |a_{n} - L| < \epsilon $.
\begin{equation}
\forall \epsilon > 0 \quad \exists N \in \N \quad s.t \quad \forall n > N \quad |a_{n} - L| < \epsilon
\end{equation}
\paragraph{Tends to infinity (sequence)}
We say a sequence tends to infinity if for all $ R \in \R $, the sequence $ a_{n} $ is eventually bigger than $ R $.
\begin{equation}
\forall R \in \R \quad \exists N \in \N \quad s.t. \quad \forall n > N \quad a_{n} > R
\end{equation}
\paragraph{Shift}
The shift of a sequence by say, k, is the sequence $ b_{n} = a_{n + k} $
\paragraph{Triangle inequality}
The general triangle inequality is:
\begin{equation}
|x - y| < |x - z| + |z - y|
\end{equation}
Setting $ z = 0 $ gives us:
\begin{align}
|x - y| & > |x| - |y|
\end{align}
Then setting $ y = - y $ gives us the familiar case:
\begin{align}
|x + y| & < |x| + |y|
\end{align}
\paragraph{Bounded above}
A sequence $ a_{n} $ is bounded above if there's a real number $ A $ such that $ a_{n} < A $ for all $ n $.
\paragraph{Bounded below}
A sequence $ a_{n} $ is bounded below if there's a real number $ A $ such that $ a_{n} > A $ for all $ n $.
\paragraph{Bounded}
A sequence $ a_{n} $ is bounded if there's a real number $ A $ such that $ |a_{n}| < A $ for all $ n $.
\paragraph{Increasing}
A sequence is increasing if $ a_{n + 1} \geq a_{n} $ for all n.
\paragraph{Strictly increasing}
A sequence is strictly increasing if $ a_{n + 1} > a_{n} $ for all n.
\paragraph{Decreasing}
A sequence is decreasing if $ a_{n + 1} \leq a_{n} $ for all n.
\paragraph{Strictly decreasing}
A sequence is strictly decreasing if $ a_{n + 1} < a_{n} $ for all n.
\paragraph{Monotonic}
A sequence is monotonic if it is increasing or decreasing.
\paragraph{Supremum}
The supremum A of a set $ S $ is the least upper bound of that set i.e. the smallest number such that $ s \leq A $ for all $ s \in S $.
\paragraph{Supremum (function)}
The supremum of a function $ f $ is the sup of $ \{f(x) | x \in \textrm{dom}(f)\} $.
\paragraph{Infimum}
The infimum B of a set $ S $ is the greatest lower bound of that set i.e. the largest number such that $ s \geq B $ for all $ s \in S $.
\paragraph{Infimum (function)}
The infimum of a function $ f $ is the inf of $ \{f(x) | x \in \textrm{dom}(f)\} $.
\paragraph{Subsequence}
A subsequence of $ a_{n} $ is a sequence $ a_{f(n)} $, where $ f(n) $ is a strictly increasing function.
\paragraph{Cauchy sequence}
A sequence is Cauchy if all the terms get arbitrarily close to one another. To put it mathematically:
\begin{equation}
\forall \epsilon > 0 \quad \exists N \in \N \quad s.t \quad \forall m,n \geq N \quad |a_{n} - a_{m}| < \epsilon
\end{equation}
\paragraph{Partial sum}
The $ n^{th} $ partial sum $ S_{n} $ of a sequence $ a_{n} $ is the sum of terms up to that point:
\begin{equation}
S_{n} = \sum_{i=1}^{n} a_{n}
\end{equation}
\paragraph{Summable}
A sequence is summable if the sequence of its partial sums converges. The limit of the sequence of partial sums will be:
\begin{equation}
L = \sum_{i=1}^{\infty} a_{n}
\end{equation}
\paragraph{Absolutely summable}
A sequence $ a_{n} $ is absolutely summable if $ |a_{n}| $ is summable.
\paragraph{Conditionally summable}
A sequence is conditionally summable if it is summable but not absolutely summable.
\paragraph{Power series}
The power series associated with a sequence $ a_{n} $ is the sequence of partial sums:
\begin{equation}
\sum_{i=1}^{n} a_{i}x^{i}
\end{equation}
\paragraph{Radius of convergence}
The radius of convergence R of a power series $ P(x) $ is defined as the largest $ x $ for which $ P(x) $ is convergent.
\begin{equation}
R = sup\{x \in \R | P(x) \textrm{ convergent}\}
\end{equation}
\paragraph{Limit as $ x \to \infty $ (function)}
A function $ f(x) $ tends to a limit $ L $ as $ x \to \infty $ if for all real numbers $ \epsilon > 0 $, there exists an $ R \in \R $ such that for all $ x \geq R $ we have $ |f(x) - L| < \epsilon $.
\begin{equation}
\forall \epsilon > 0 \quad \exists R \in \R \quad s.t \quad \forall x > R \quad |f(x) - L| < \epsilon
\end{equation}
\paragraph{Tends to infinity (function)}
A function $ f(x) $ tends to infinity as $ x \to \infty $ if for any $ M \in \R $ there exists an $ R \in \R $ such that if $ x > M $ then $ f(x) > R $.
\begin{equation}
\forall M \in \R \quad \exists R \in \R \quad s.t. \quad x > M \Rightarrow f(x) > R
\end{equation}
\paragraph{One-sided limit (function)}
A function $ f(x) $ tends to a limit $ L $ as $ x \to a^{-} $ if for any $ \epsilon > 0 $ there exists a $ \delta > 0 $ such that if $ x \in (a - \delta, a) $ then $ |f(x) - L| < \epsilon $.
\begin{equation}
\forall \epsilon > 0 \quad \exists \delta > 0 \quad s.t. \quad x \in (a - \delta, a) \Rightarrow |f(x) - L| < \epsilon
\end{equation}
\noindent Same format for the other sided limit ($ x \to a^{+} $)
\\
(Note that $ \epsilon - \delta $ definition is only used for limits as x tends to a finite number a, not infinity)
\paragraph{Limit as $ x \to a $ (function)}
A function $ f(x) $ tends to a limit $ L $ as $ x \to a $ if we have both:
\begin{equation}
\lim_{x \to a^{-}}f(x) = L \quad \textrm{and} \quad \lim_{x \to a^{+}}f(x) = L
\end{equation}
\paragraph{Continuous (ver. 1)}
A function $ f(x) $ is continuous at a if:
\begin{equation}
\lim_{x \to a}f(x) = f(a)
\end{equation}
\paragraph{Continuous (ver. 2)}
A function $ f(x) $ is continuous at a if for all $ \epsilon > 0 $ there is a $ \delta > 0 $ such that if $ |x - a| < \delta $ then $ |f(x) - f(a)| < \epsilon $.
\begin{equation}
\forall \epsilon > 0 \quad \exists \delta > 0 \quad s.t. \quad |x - a| < \delta \Rightarrow |f(x) - f(a)| < \epsilon
\end{equation}
\paragraph{Continuous everywhere}
A function $ f(x) $ is continuous everywhere if it is continuous at a for all $ a \in \textrm{dom}(f) $.
\paragraph{Open interval}
An open inteval $ I $ is a set $ I \subseteq \R $ of the form:
\begin{enumerate}
\item $ I = (a, b) $ for some $ a, b \in \R $, or
\item $ I = (-\infty, b) $, or
\item $ I = (a, +\infty) $, or
\item $ I = \R $
\end{enumerate}
\paragraph{Discontinuity}
Discontinuity is the negation of continuity. Hence a function $ f(x) $ is discontinuous at a if there exists $ \epsilon > 0 $ such that for all $ \delta > 0 $, $ |x - a| < \delta $ AND $ |f(x) - f(a)| > \epsilon $.
\begin{equation}
\exists \epsilon > 0 \quad s.t. \quad \forall \delta > 0 \quad |x - a| < \delta \textrm{ AND } |f(x) - f(a)| > \epsilon
\end{equation}
\paragraph{Bounded (function)}
A function $ f(x) $ is bounded if the set of all possible values of f(x) is bounded.
\paragraph{Differentiable (ver. 1)}
A function $ f(x) $ is differentiable at a if:
\begin{equation}
\lim_{x \to a}\frac{f(x) - f(a)}{x - a}
\end{equation}
exists.
\paragraph{Differentiable (ver. 2)}
A function $ f(x) $ is differentiable at a if:
\begin{equation}
\lim_{h \to 0}\frac{f(a + h) - f(a)}{h}
\end{equation}
exists.
\paragraph{Differentiable everywhere}
A function $ f(x) $ is differentiable everywhere if it is differentiable at a for all $ a \in \textrm{dom}(f) $.
\paragraph{Global maximum}
A function $ f(x) $ has a global maximum at a if $ f(a) \geq f(x) $ for all other values of $ f(x) $.
\\\\
Similar definition for global minimum.
\paragraph{Local maximum}
A function $ f(x) $ has a local maximum at a if $ f(a) \geq f(x) $ for all x in the set $ (a - \epsilon, a + \epsilon) $, for some $ \epsilon $.
\\\\
Similar definition for local minimum.
\paragraph{Lipschitz continuous}
A function is Lipschitz continuous if:
\begin{equation}
|f'(x)| \leq L \Rightarrow |f(x_{1}) - f(x_{2})| \leq L|x_{1} - x_{2}|
\end{equation}

\section{Theorems}
\subsection{Sequences}
Every convergent sequence has a unique limit.
\\\\
Every convergent sequence is bounded.
\\\\
If all terms of a convergent sequence are larger than a number $ B $, then so is its limit.
\\\\
Some properties of limits:
\begin{align}
\lim_{x \to \infty}(a_{n} + b_{n}) & = \lim_{x \to \infty} a_{n} + \lim_{x \to \infty} b_{n} \\
\lim_{x \to \infty}(\lambda a_{n}) & = \lambda\lim_{x \to \infty} a_{n} \\
\lim_{x \to \infty}(a_{n}b_{n}) & = \lim_{x \to \infty} a_{n}\lim_{x \to \infty} b_{n} \\
\lim_{x \to \infty}(\frac{a_{n}}{b_{n}}) & = \frac{\lim_{x \to \infty} a_{n}}{\lim_{x \to \infty} b_{n}}
\end{align}
where $ \lambda $ is any real number.
\\\\
If $ a_{n} \to \infty $ and $ b_{n} $ is bounded below, $ a_{n} + b_{n} \to \infty $.
\\\\
If $ a_{n} \to \infty $ and $ b_{n} $ is bounded below by a positive number, $ a_{n}b_{n} \to \infty $.
\\\\
If $ a_{n} $ is bounded and $ b_{n} \to \infty $, then $ \frac{a_{n}}{b_{n}} \to 0 $.
\\\\
If $ a_{n} \to \infty $, for any real number $ \lambda $:
\begin{itemize}
\item $ \lambda < 0 \Rightarrow \lambda a_{n} \to -\infty $
\item $ \lambda = 0 \Rightarrow \lambda a_{n} \to 0 $
\item $ \lambda > 0 \Rightarrow \lambda a_{n} \to \infty $
\end{itemize}
If $ a_{n} \to a $ and $ b_{n} \to b $, and for all $ n $ $ a_{n} < b_{n} $, then $ a < b $.
\\\\
\textit{Sandwich Theorem}
\\
If $ a_{n} \leq b_{n} \leq c_{n} $ for all n, and $ a_{n} $ and $ c_{n} $ tend to the same limit $ L $, then $ b_{n} \to L $.
\\\\
Every bounded monotonic sequence is convergent.
\\\\
\textit{Completeness Axiom}
\\
Every non-empty subset of the real numbers which is bounded above has a supremum. Similar statement for infimum.

\subsection{Subsequences}
If $ a_{n} \to L $ then any subsequence $ a_{f(n)} \to L $.
\\\\
If two subsequences of $ a_{n} $ converge to different limits, $ a_{n} $ doesn't converge to a limit.
\\\\
Every sequence has a monotonic subsequence.
\\\\
\textit{Bolzano-Weierstrass Theorem}
\\
Every bounded sequence has a convergent subsequence.
\\\\
Every Cauchy sequence is bounded.
\\\\
Cauchy sequence $ \Leftrightarrow $ convergent sequence (for real numbers).
\\\\
\hspace*{-1in}
\includegraphics[scale=0.4]{sequences}

\subsection{Summability}
A sequence is summable iff the sequence of its partial sums converges.
\\\\
If two subsequences of a sequence $ a_{n} $ converge to two different limits, $ a_{n} $ is not summable.
\\\\
If $ a_{n} $ and $ b_{n} $ are summable with $ \sum_{i = 0}^{\infty} a_{i} = a $ and $ \sum_{i = 0}^{\infty} b_{i} = b $:
\begin{itemize}
\item $ a_{n} + b_{n} $ is summable with $ \sum_{i = 0}^{\infty} (a_{i} + b_{i}) = a + b $.
\item $ \lambda a_{n} $ is summable with $ \sum_{i = 0}^{\infty} \lambda a_{i} = \lambda a $ (for any real number $ \lambda $)
\end{itemize}
If $ b_{n} = a_{n + k} $ then $ a_{n} $ summable $ \Leftrightarrow b_{n} $ summable.
\\\\
$ a_{n} $ is summable $ \Rightarrow a_{n} \to 0 $.
\\\\
Let $ S_{n} $ denote the sequence of partial sums of $ a_{n} $ ($ S_{n} = \sum_{i = 0}^{n} a_{n}) $. A sequence of non-negative numbers $ a_{n} $ is summable iff $ S_{n} $ is bounded above. Similar statement for sequences of non-positive numbers.
\\\\
Every absolutely summable sequence is summable.
\\\\
\textit{Comparison test}
\\
If $ b_{n} > a_{n} $ for all $ n $ then $ b_{n} $ summable $ \Rightarrow a_{n} $ summable.
\\\\
\textit{Alternating series test}
\\
If $ a_{n} $ is a decreasing sequence AND $ a_{n} \geq 0 $ for all $ n $ AND $ a_{n} \to 0 $ then $ (-1)^{n+1} a_{n} $ is a convergent sequence.
\\\\
\textit{Ratio test}
\\
Let $ r = \lim_{n \to \infty} \frac{a_{n + 1}}{a_{n}} $:
\begin{itemize}
\item $ r < 1 \Rightarrow a_{n} $ is absolutely summable
\item $ r > 1 \Rightarrow a_{n} $ is not summable
\item $ r = 1 $ is an indeterminate case
\end{itemize}

\subsection{Power series}
The power series associated with a sequence $ a_{n} $ converges iff the sequence of partial sums  of $ a_{n}x^{n} $ converges (i.e. if $ \sum_{i = 0}^{n} a_{i}x^{i} $ converges).
\\\\
Let $ P(x) $ be a power series. If $ P(a) $ converges absolutely for some $ a $, then $ P(x) $ converges absolutely for all $ x $ such that $ |x| < |a| $
\\\\
Let $ R $ be the radius of convergence of $ P(x) $. For all real numbers $ a $:
\begin{itemize}
\item $ |a| < R \Rightarrow P(a) $ converges absolutely
\item $ |a| > R \Rightarrow P(a) $ diverges
\end{itemize}
Let $ r = \frac{a_{n + 1}}{a_{n}} $. Let $ P(x) = \sum_{i = 0}^{n} a_{i}x^{i} $ (i.e. the power series associated with $ a_{n} $):
\begin{itemize}
\item $ r \to 0 \Rightarrow R = \infty $
\item $ r \to L $ for some $ L \Rightarrow R = \frac{1}{L} $
\item $ r \to \infty \Rightarrow R = 0 $
\end{itemize}

\subsection{Continuity}
The limit of a function at any specific point is unique.
\\\\
If functions $ f $ and $ g $ are continuous at a:
\begin{itemize}
\item $ (f + g) $ is continuous at a
\item $ fg $ is continuous at a
\item $ \frac{1}{f(x)} and \frac{1}{g(x)} $ are continuous at a
\item $ g \circ f $ is continuous at a
\end{itemize}
Any polynomial in $ \R $ is continuous
\\\\
Any rational function in $ \R $ is continuous
\\\\
\textit{Sequential continuity}
\\
A function $ f $ is continuous at $ a $ iff $ f(a_{n}) \to f(a) $ for all sequences $ a_{n} $ such that $ a_{n} \to a $.
\\\\
Any continuous function on a closed bounded interval is bounded.
\\\\
\textit{Intermediate Value Theorem}
\\
If $ f $ continuous and $ f(a) \leq f(b) $ for some $ a, b $, then there exists some $ c \in [a, b] $ such that $ f(a) \leq f(c) \leq f(b) $.
\\\\
\textit{Fixed Point Theorem}
\\
If $ f $ continuous and $ f: [a, b] \to [a, b] $, then there exists some $ c \in [a, b] $ such that $ f(c) = c $.
\\\\
Polynomials of odd degree have at least 1 root.
\\\\
$ f $ differentiable $ \Rightarrow f $ continuous.
\subsection{Differentiable functions}
If functions $ f $ and $ g $ are differentiable at a:
\begin{itemize}
\item $ (f + g) $ is differentiable at a
\item $ fg $ is differentiable at a
\item $ \frac{1}{f(x)} and \frac{1}{g(x)} $ are differentiable at a
\item $ g \circ f $ is differentiable at a
\item $ g^{-1} $ and $ f^{-1} $ are differentiable at a
\end{itemize}
Let $ f $ be continuous and differentiable. If $ f $ has a local extremum at $ a $ then $ f'(a) = 0 $ (except at endpoints of the interval).
\\\\
Let $ f $ be continuous and differentiable. If $ f $ has a local extremum at $ c $ (say in the interval $ [a, b] $), there are 3 possiblities:
\begin{itemize}
\item $ c $ is an endpoint of $ [a, b] $
\item $ f'(c) = 0 $
\item $ c $ is a non-differentiable point
\end{itemize}
\textit{Mean Value Theorem}
\\
Let $ f $ be continuous on $ [a, b] $ and differentiable on $ (a, b) $. There exists a point $ c \in (a, b) $ such that:
\begin{equation}
f'(c) = \frac{f(b) - f(a)}{b - a}
\end{equation}
\\\\
\textit{Rolle's Theorem}
\\
Let $ f $ be continuous and differentiable on $ (a, b) $. If $ f(a) = f(b) $ then there exists some $ c \in (a, b) $ such that $ f'(c) = 0 $. This is a special case of the Mean Value Theorem.

\end{document}