%added document class from KOMA-Script
\documentclass{scrartcl}
\title{Differential Equations Cheatsheet}
\subtitle{JMC Year 1, 2017/2018 syllabus}
\date{}
\author{Fawaz Shah}

% Packages for adding hyperlinks to table of contents
\usepackage{color}   %May be necessary if you want to color links
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=black,  %choose some color if you want links to stand out
}

%package that allows aligned equations
\usepackage{amsmath}


\begin{document}
\large
\maketitle
\noindent Topics not covered in this summary: phase portraits, similarity transformations.
\tableofcontents
\newpage
\section{Definitions}

\paragraph{Order (of derivative)}
An $ n^{th} $ derivative has order $ n $.

\paragraph{Order (of ODE)}
The order of the highest derivative present in an ODE.

\paragraph{Degree (of ODE)}
The highest power to which a term is raised in an ODE (excluding fractional powers).

\paragraph*{Linear (ODE)}
An ODE which has no terms raised to more than the $ 1^{st} $ power, and with no $ y, x $ or other derivative terms multiplied by each other.

\paragraph{System of diff. equations}
A set of simultaneous equations of derivatives, where derivatives of $ y, x $ etc. are given w.r.t. a parameter $ t $

\paragraph{Order (of system)}
The order of the highest derivative present in the system.

\paragraph{Degree (of system)}
The highest power to which a term is raised in an ODE (excluding fractional powers).

\paragraph{Linear (system)}
A system which has no terms raised to more than the $ 1^{st} $ power, and with no $ y $ or other derivative terms multiplied by each other.

\paragraph{Homogeneous (system)}
A system with no explicit functions of $ t $ (i.e. $ f(t) $) present.
    
\section{1st order linear ODEs}
Every 1st order linear ODE can be expressed as:
\begin{equation}
\frac{dy}{dx} + p(x)y = q(x)
\end{equation}
These can ALL be solved by the \emph{integrating factor} method:
\begin{enumerate}
\item Multiply both sides by $ exp(\int_{}^{} p(x) \ dx) $
\item Use the reverse product rule to express the LHS as a single derivative (of a function of y).
\item Integrate both sides and rearrange.
\end{enumerate}
  
\section{1st order non-linear ODEs}

\subsection{Exact equations}
Let us say we have an ODE of the form:
\begin{equation}
P(x, y) + Q(x, y)\frac{dy}{dx} = 0
\end{equation}
(note the coefficients are multi-variable functions). This can be rewritten as:
\begin{equation} \label{exactdifferential}
P(x, y) dx + Q(x, y) dy = 0
\end{equation}
We can try the exact equations method. We say an equation is exact iff:
\begin{equation}
\frac{\partial P}{\partial y} \equiv \frac{\partial Q}{\partial x} 
\end{equation}
This simple condition implies some important results. It can be shown that an exact equation implies the LHS of equation \ref{exactdifferential} is an exact (total) differential). This means it can be written as $ df $, where f is some function of $ x $ and $ y $. But the equation of this total differential is:
\begin{equation}
df = \frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y}dy
\end{equation}
Comparing to equation \ref{exactdifferential} we can note 3 things:
\begin{equation}
\begin{split}
P(x, y) & = \frac{\partial f}{\partial x} \\
Q(x, y) & = \frac{\partial f}{\partial y} \\
df & = 0
\end{split}
\end{equation}
We integrate $ P(x, y) $ w.r.t $ x $ and $ Q(x, y) $ w.r.t $ y $ and 'merge' the two expressions together (i.e. for any matching terms, write them down only once) to give us an expression for $ f(x, y) $. Ignore constants of integration. $ df = 0 $ tells us that $ f(x, y) = c $ by integration. Therefore the general solution is given by:
\begin{equation}
f(x, y) = c
\end{equation}
for some arbitrary constant c.

\subsection{Separable ODEs}
Separable equations can be written in the form:
\begin{equation}
\frac{dy}{dx} = f(x)g(y)
\end{equation}
These can be rearranged and integrated on both sides, with respect to the different variables.

\subsection{Homogenous ODEs}
Homogenous equations can be written in the form:
\begin{equation}
\frac{dy}{dx} = f(\frac{y}{x})
\end{equation}
To solve, set $ v = \frac{y}{x} $, so that $y = xv $. Note that v is still a single-variable function of x, since y is a function of x.
Now we can differentiate both sides to get:
\begin{equation}
\frac{dy}{dx} = v + x\frac{dv}{dx}
\end{equation}
We now have simultaneous equations for $ \frac{dy}{dx} $. Equate and solve for $ \frac{dv}{dx} $, and then solve this 1st order linear ODE in $ \frac{dv}{dx} $ to find v (and then y).

\subsection{Bernoulli type ODEs}
A Bernoulli type ODE is of the form:
\begin{equation}
\frac{dy}{dx} + p(x)y = q(x)y^n
\end{equation}
To solve:
\begin{enumerate}
\item Multiply both sides by $ (1-n)y^{-n} $
\item Let $ z = y^{1-n} $ and substitute into equation, including rewriting one of the terms as $ \frac{dz}{dx} $
\item The resulting equation is 1st order linear in z, so solve for z (and then y).
\end{enumerate}

\section{2nd order ODEs}

\subsection{Special case - y missing}
If we can write the $ 2^{nd} $ derivative in the form:
\begin{equation}
\frac{d^{2}y}{dx^{2}} = f(x, \frac{dy}{dx})
\end{equation}
(i.e. no $ y $ terms present), then we can make a substitution. Let $ P = \frac{dy}{dx} $. This means $ \frac{d^{2}y}{dx^{2}} = \frac{dP}{dx} $, the
refore we have:
\begin{equation}
\frac{dP}{dx} = f(x, P)
\end{equation}
This is 1st order w.r.t P and can be solved by appropriate 1st order methods.

\subsection{Special case - x missing}
If we can write the $ 2^{nd} $ derivative as:
\begin{equation}
\frac{d^{2}y}{dx^{2}} = f(y, \frac{dy}{dx})
\end{equation}
(i.e. no x terms present), then we can make the same substitution. Let $ P = \frac{dy}{dx} $. This means $ \frac{d^{2}y}{dx^{2}} = \frac{dP}{dx} $, therefore we have:
\begin{equation}
\frac{dP}{dx} = f(y, P)
\end{equation}
However, this is not yet a 1st order equation since the derivative is w.r.t. x, but we only have y terms on the RHS.
\\\\
DIFFERENT TO LAST TIME: we must rewrite $ \frac{dP}{dx} $ as a derivative with respect to y. Luckily, we can see that:
\begin{equation}
\frac{dP}{dx} = \frac{dP}{dy}\frac{dy}{dx} = P\frac{dP}{dy}
\end{equation}
Therefore:
\begin{equation}
P\frac{dP}{dy} = f(y, P)
\end{equation}
This is 1st order w.r.t P and can be solved by appropriate 1st order methods.

\subsection{General case - finding the CF}
The general solution (GS) of a 2nd order ODE can be expressed as the sum of two other functions, called the 'complementary function' (CF) and a 'particular integral' (PI).
\begin{equation}
y_{GS} = y_{CF} + y_{PI}
\end{equation} 
A 2nd order ODE will usually be presented to us in the form:
\begin{equation} \label{secondordergeneralform}
a\frac{d^{2}y}{dx^{2}} + b\frac{dy}{dx} + c = f(x)
\end{equation}
It can be shown that the CF can be calculated from the LHS of the above equation. We write down the \emph{auxiliary equation}, which is simply the equation:
\begin{equation}
a\lambda^{2} + b\lambda + c = 0
\end{equation}
using a, b, c from above. Solving this gives us two values, $ \lambda_{1} $ and $ \lambda_{2} $.

\subsubsection*{Case 1: $ \lambda_{1} \neq \lambda_{2} $, both real}
We can express the CF as:
\begin{equation}
y_{CF} = A_{1}e^{\lambda_{1}x} + A_{2}e^{\lambda_{2}x}
\end{equation}
where $ A_{1} $ and $ A_{2} $ are arbitrary constants.

\subsubsection*{Case 2: $ \lambda_{1} = \lambda_{2} $, both real}
Same as above, but we stick an $ x $ in front of one of the clashing parts of the solution.
\begin{equation}
y_{CF} = A_{1}e^{\lambda_{1}x} + A_{2}xe^{\lambda_{2}x}
\end{equation}

\subsubsection*{Case 3: $ \lambda_{1} $, $ \lambda_{2} $ are complex}
If the auxiliary equation has complex roots, $ \lambda_{1} $ and $ \lambda_{2} $ will be complex conjugates. The CF can be expressed as:
\begin{equation}
\begin{split}
y_{CF} & = A_{1}e^{(a + bi)x} + A_{2}e^{(a - bi)x} \\
       & = e^{a}(A_{1}e^{i(bx)} + A_{2}e^{- i(bx)}) \\
       & = e^{a}(C_{1}cos(bx) + C_{2}sin(bx))
\end{split}
\end{equation}
where $ C_{1} = A_{1} + A_{2} $ and $ C_{2} = (A_{1} - A_{2})i $. Note that even though $ A_{1} $ and $ A_{2} $ may have been complex, $ C_{1} $ and $ C_{2} $ are necessarily real.

\subsection{General case - finding the PI}
The particular integral is \emph{any function $ y_{PI} $ that satisfies the ENTIRE differential equation}. The particular integral can be calculated depending on the form of the RHS of equation \ref{secondordergeneralform}. We will refer to the RHS as simply $ f(x) $ and the particular integral (as before) as $ y_{PI} $. We can follow some basic rules:


\subsubsection*{Case 1: $ f(x) $ is a polynomial}
Try setting $ y_{PI} $ as a general polynomial of the same degree. e.g. if $ f(x) $ is a quadratic, try setting $ y_{PI} = ax^{2} + bx + c $ and substituting into the ODE. We will solve for a, b, c, and this will give us $ y_{PI} $.

\subsubsection*{Case 2: $ f(x) $ is a multiple of $ e^{bx} $, $ e^{bx} $ NOT in CF}
Choose $ y_{PI} = Ae^{bx} $ for some real number A.

\subsubsection*{Case 3: $ f(x) $ is a multiple of $ e^{bx} $, $ e^{bx} $ IS in CF}
We now have a clash between the PI and the CF. We can try $ y_{PI} = Axe^{bx} $, i.e. sticking an x in the PI to avoid the clash. If this doesn't work, we can choose $ y_{PI} = A(x)e^{bx} $ for some real FUNCTION A. Remember to use the CHAIN RULE to differentiate A this time.
\\\\
At the end remove any clashing terms, i.e. terms of the form $ Be^{\lambda x} $ where $ e^{\lambda x} $ is already present in the CF. Other terms with more $ x $'s included are allowed, e.g. $ xe^{\lambda x} $ would not count as a clashing term.

\subsubsection*{Case 4: $ f(x) = A(x)e^{bx} $ where $ A(x) $ is a polynomial}
Choose $ y_{PI} = C(x)e^{bx} $ for some polynomial $ C(x) $.

\subsubsection*{Case 5: $ f(x) $ is trigonometric (e.g. sin, cos, sinh etc.)}
Look for a pattern in $ f(x) $. A good tip for an $ f(x) $ with only sines/cosines is to use $ y_{PI} = A\cos(x) + B\sin(x) $ and solve for A and B. A similar story for sinh and cosh.
CAUTION: sinh, cosh and tanh are actually exponential functions in disguise, so make sure they do not clash with any $ e^{\lambda x} $ terms in the CF.

\subsubsection*{Other cases}
If $ f(x) $ has a term of the form $ e^{x}\cos(x) $ or $ e^{x}\sin(x) $ then we can rewrite it as the real/imaginary part of a complex function (in this case $ e^{(1+i)x} $ would be appropriate, since it expands to $ e^{x}(\cos(x) + i\sin(x)) $.
\\\\
If $ f(x) $ is more complicated, we may have to be imaginative with the choice of $ y_{PI} $. e.g. for $ f(x) = Ae^{ax} + Be^{bx} $ we could choose $ y_{PI} = Ce^{ax} + De^{bx} $ for some constants $ C, D $. Again be careful of terms that clash with the CF.

\section{Solving systems of differential equations}
A homogeneous 1st order system of equations can be written as:
\begin{equation}
\begin{split}
\frac{dx}{dt} & = F(x, y) \\
\frac{dy}{dt} & = G(x, y)
\end{split}
\end{equation}
Let us choose an example coupled system:
\begin{equation}
\begin{split}
\frac{dx}{dt} & = ax + by \\
\frac{dy}{dt} & = cx + dy
\end{split}
\end{equation}
We can rewrite this in matrix form:
\begin{equation}
\frac{d}{dt}
\begin{pmatrix}
x \\
y
\end{pmatrix}
=
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
\begin{pmatrix}
x \\
y
\end{pmatrix}
\end{equation}
The system is now of the form
\begin{equation}
\frac{d}{dt}v = Mv
\end{equation}
If we set $ v = Ve^{\lambda  t} $, where V is a constant vector independent of $ x, y $ or $ t $, then we get
\begin{equation}
\begin{split}
\lambda V & = MV \\
(M - \lambda I_{n})V & = 0_{v} \\
\det(M - \lambda I_{n}) & = 0
\end{split}
\end{equation}
Predictably, we find two eigenvalues $ \lambda_{1} ,  \lambda_{2} $ and (any) two eigenvectors $ v_{1},  v_{2} $. The solution to the system is given by:
\begin{equation}
\begin{pmatrix}
x \\
y
\end{pmatrix}
= A_{1}v_{1}e^{\lambda_{1}t} + A_{2}v_{2}e^{\lambda_{2}t}
\end{equation}
The dimension of the eigenvectors will always match the number of variables being dealt with, for example a possible scenario is:
\begin{equation}
\begin{pmatrix}
x \\
y
\end{pmatrix}
= A_{1}
\begin{pmatrix}
3 \\
-5
\end{pmatrix}
e^{-3t} + A_{2}
\begin{pmatrix}
7 \\
-2
\end{pmatrix}
e^{2t}
\end{equation}
The values of the individual derivatives can be found by reading off the rows of the matrices.
\begin{equation}
\begin{split}
x & = 3A_{1}e^{-3t} + 7A_{2}e^{2t} \\
y & = -5A_{1}e^{-3t} + -2A_{2}e^{2t}
\end{split}
\end{equation}

\subsubsection*{Complex eigenvalues}
If the eigenvalues turn out to be complex conjugates, the solution can be written as:
\begin{equation}
\begin{pmatrix}
x \\
y
\end{pmatrix}
= A_{1}v_{1}e^{(a + bi)t} + A_{2}v_{2}e^{(a - bi)t}
\end{equation}
(Note that $ A_{1} $ and $ A_{2} $ may be complex). We can do some rearranging like before to tidy up the solution:
\begin{equation}
\begin{split}
\begin{pmatrix}
x \\
y
\end{pmatrix}
& = A_{1}v_{1}e^{(a + bi)t} + A_{2}v_{2}e^{(a - bi)t} \\
& = e^{a}(A_{1}v_{1}e^{i(bt)} + A_{2}v_{2}e^{- i(bt)}) \\
& = e^{a}(C_{1}\cos(bt) + C_{2}\sin(bt))
\end{split}
\end{equation}
where $ C_{1} = A_{1}v_{1} + A_{2}v_{2} $ and $ C_{2} = (A_{1}v_{1} - A_{2}v_{2})i $. Note that $ C_{1} $ and $ C_{2} $ are vectors.

\end{document}
